

# Expo + TypeScript Mock App Design for Japanese Learning App

Based on the **Japanese Learning App** requirements ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1))  ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1,%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E3%81%AE%E6%9F%94%E8%BB%9F%E3%81%AA%E5%86%8D%E5%88%A9%E7%94%A8%E3%83%BB%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%20JSON%E5%BD%A2%E5%BC%8F%E3%81%AE%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%E5%AE%9A%E7%BE%A9%E3%81%A7%E3%80%81%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%82%92%E6%9C%80%E5%B0%8F%E5%8D%98%E4%BD%8D%E3%81%A8%E3%81%97%E3%80%81%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%BC%E3%83%89%EF%BC%88%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E7%89%B9%E5%8C%96%E3%80%81%E3%82%AF%E3%82%A4%E3%82%BA%E7%89%B9%E5%8C%96%E3%80%81%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%AA%E3%82%B9%E3%83%88%E3%81%AA%E3%81%A9%EF%BC%89%E3%81%AB%E5%BF%9C%E3%81%98%E3%81%A6%E8%87%AA%E7%94%B1%E3%81%AB%E5%86%8D%E5%88%A9%E7%94%A8%E5%8F%AF%E8%83%BD))  we will design a cross-platform mobile app (iOS & Android) using **Expo (latest)** and **TypeScript**. The app will provide balanced **input learning** (vocabulary/phrases with readings, translations, audio) and **output practice** (speaking with pronunciation feedback) as described in the README ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1))  All external API calls (e.g. speech recognition) will be **mocked** with in-app data and logic, and no real network calls are made. We focus on a clean architecture with maintainable code, using best practices suitable for a senior engineer level.

## 1. Directory Structure

We'll organize the project into a clear folder hierarchy under a `src/` directory, separating components, screens, navigation, state management, services (mock API), types, and assets. This structure improves maintainability and scalability:

```
japanese-learning-app/    (Expo project root)
├── App.tsx                # Entry point of the application
├── app.json               # Expo app configuration
├── package.json           # Project dependencies and scripts
├── tsconfig.json          # TypeScript configuration (strict typing)
├── assets/                # Static assets (images, audio, data)
│   ├── data/
│   │   └── content.json   # Local JSON data for lessons, phrases, quizzes (mock content)
│   └── audio/             # Audio files for pronunciation (e.g., .mp3 for phrases)
└── src/                   # Application source code
    ├── components/        # Reusable UI components
    │   ├── PhraseCard.tsx         # Component to display a phrase with text, reading, etc.
    │   ├── QuizOption.tsx         # Component for a single quiz option (button)
    │   ├── AudioPlayer.tsx        # Component or hook for playing audio (using Expo AV)
    │   └── MicButton.tsx          # Microphone button UI (for output practice)
    ├── screens/           # Screen components for each app page
    │   ├── HomeScreen.tsx         # Home screen (lesson list & navigation to modes)
    │   ├── LessonDetailScreen.tsx # Lesson detail (shows mini-lessons and progress)
    │   ├── PhrasePracticeScreen.tsx # Phrase learning screen with Input/Output tabs
    │   ├── QuizScreen.tsx         # Quiz screen (multiple-choice questions)
    │   └── CustomListScreen.tsx   # (Optional) User’s custom list screen for favorite phrases
    ├── navigation/        # Navigation configuration (React Navigation)
    │   ├── AppNavigator.tsx       # Stack navigator defining screen transitions
    │   └── types.ts               # Navigation param types for type safety
    ├── context/           # Context providers for global state management
    │   ├── ContentContext.tsx     # Provides lesson/phrase content data to components
    │   └── ProgressContext.tsx    # Tracks user progress (completed lessons, favorites)
    ├── services/          # API simulation and business logic
    │   ├── contentService.ts      # Functions to fetch content from local JSON (mock API)
    │   ├── quizService.ts         # Functions to generate/score quiz questions (mock logic)
    │   └── speechService.ts       # Functions to simulate speech evaluation results
    ├── types/             # TypeScript type definitions for data models
    │   ├── content.types.ts      # Interfaces for Lesson, MiniLesson, Phrase, QuizQuestion
    │   └── app.types.ts          # Other shared types (e.g., for context value shapes)
    └── utils/             # Utility functions (helpers)
        ├── audioUtils.ts          # Helper to load/play audio files (wrapping Expo AV)
        └── formatUtils.ts         # Formatting helpers (e.g., for quiz feedback or text)
```

**Notes:** Expo's default structure (including **App.tsx**, **app.json**, and **assets/**) is preserved for compatibility. All app code lives in `src/` for clarity. This modular structure aligns with best practices, making it easy to maintain and extend. iOS and Android are both supported by using Expo and React Native (as suggested in the requirements ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E9%9F%B3%E5%A3%B0%E8%AA%8D%E8%AD%98%E9%83%A8%E5%88%86%E3%81%AF%E3%82%AA%E3%83%B3%E3%83%A9%E3%82%A4%E3%83%B3%E5%BF%85%E9%A0%88%E3%81%A0%E3%81%8C%E3%80%81%E3%82%AA%E3%83%95%E3%83%A9%E3%82%A4%E3%83%B3%E5%AD%A6%E7%BF%92%E7%94%A8%E3%81%AB%E3%82%AF%E3%82%A4%E3%82%BA%E3%82%84%E5%8D%98%E8%AA%9E%E5%B8%B3%E3%82%92%E3%82%AD%E3%83%A3%E3%83%83%E3%82%B7%E3%83%A5%E3%81%99%E3%82%8B%E4%BB%95%E7%B5%84%E3%81%BF%E3%82%82%E6%A4%9C%E8%A8%8E%E5%8F%AF)) , with most code shared across platforms.

## 2. Responsibilities of Each File/Module

Each file and module has a clear responsibility to enforce separation of concerns:

- **App.tsx**: The entry point of the app. It wraps the app in providers (Navigation and Context) and renders the root navigator. For example, it will include `<NavigationContainer>` (from React Navigation) and context providers like `<ContentProvider>` and `<ProgressProvider>` to make data available app-wide. It may also load the initial content from `assets/data/content.json` on startup (e.g., using Expo FileSystem or simply importing the JSON) and provide it via context.

- **assets/data/content.json**: Contains the mock content data (lessons, phrases, quizzes, etc.) in JSON format. The README specifies that content is defined in JSON with phrases as the smallest unit, including fields like text, reading, translations, audio, etc. ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E5%AD%A6%E7%BF%92%E3%82%BF%E3%82%B9%E3%82%AF%EF%BC%88%E6%8F%90%E7%A4%BA%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%EF%BC%9A%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E8%A1%A8%E7%A4%BA%E3%81%AE%E6%9C%89%E7%84%A1%E3%80%81%E9%9F%B3%E5%A3%B0%E8%A1%A8%E7%A4%BA%E3%81%AE%E6%9C%89%E7%84%A1%E3%80%81%E3%83%9E%E3%82%B9%E3%82%AD%E3%83%B3%E3%82%B0%E7%AE%87%E6%89%80%E3%81%AA%E3%81%A9%EF%BC%89))  ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,))  We will follow this structure. For example, a phrase entry might look like:  
  ```json
  {
    "id": "phrase_ohayou",
    "jp_text": "おはようございます",
    "reading": "おはようございます",
    "translations": { "en": "Good morning" },
    "audio": "audio/ohayou.mp3"
  }
  ```  
  Lessons and mini-lessons will reference these phrases (e.g., by IDs). This file acts as our “database” for the mock app, ensuring **data is stored in-app** as required (no external DB) ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%EF%BC%88JSON%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%84%E9%9F%B3%E5%A3%B0%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%EF%BC%89%E3%81%AF%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B8%EF%BC%8BCDN%E3%81%A7%E9%85%8D%E4%BF%A1)) 

- **assets/audio/**: Contains audio files for pronunciation (e.g., MP3 files for each phrase’s native pronunciation). This supports the **input learning feature of audio playback** ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E5%8D%98%E8%AA%9E%E3%83%BB%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E8%A1%A8%E7%A4%BA%20,%E5%8D%98%E8%AA%9E%E3%81%AE%E5%88%86%E6%9B%B8%EF%BC%88%E5%85%AC%E5%9C%92%EF%BC%9Dpark%20%E3%81%AA%E3%81%A9%EF%BC%89%E3%82%92%E4%BD%B5%E8%A8%98))  In the mock, we include a few sample audio files and use Expo’s AV module to play them.

- **src/navigation/AppNavigator.tsx**: Defines the navigation structure using React Navigation. We will use a **Stack Navigator** for the primary app flow. For example: 
  - `HomeScreen` (initial route) – displays main menu and lesson list.
  - `LessonDetailScreen` – shows mini-lessons in a selected lesson.
  - `PhrasePracticeScreen` – allows the user to practice phrases (with input/output tabs).
  - `QuizScreen` – presents quizzes (either at end of a lesson or speed quiz mode).  
  We configure navigation routes and their param types (in a separate `navigation/types.ts` for type safety). React Navigation helps manage moving between the Home, lesson, practice, and quiz screens easily. The structure directly reflects the UI flow described in the requirements ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E3%83%9B%E3%83%BC%E3%83%A0%E7%94%BB%E9%9D%A2%20,%E6%AC%A1%E3%81%AE%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%B8%E3%80%81%E3%81%BE%E3%81%9F%E3%81%AF%E3%82%AF%E3%82%A4%E3%82%BA%E3%81%B8%E9%80%B2%E3%82%80%E3%83%9C%E3%82%BF%E3%83%B3%204.%20%E3%82%AF%E3%82%A4%E3%82%BA%E7%94%BB%E9%9D%A2))  (If needed, we could also include a bottom tab navigator or drawer, but the spec suggests a linear flow from Home into various modes, so a simple stack is sufficient.)

- **src/screens/HomeScreen.tsx**: Displays the **Home UI**, which includes:
  - A list of available **Lessons** (categories/themes) for selection. For each lesson, show its title and possibly a progress indicator (e.g., how many phrases learned, as mentioned in UI/UX design ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=2.%20%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E8%A9%B3%E7%B4%B0%E7%94%BB%E9%9D%A2%20,%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E5%AD%A6%E7%BF%92%E7%94%BB%E9%9D%A2%EF%BC%88%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%EF%BC%89)) . Selecting a lesson navigates to `LessonDetailScreen` for that lesson.
  - Buttons or cards for special modes: **Speed Quiz**, **Output Practice**, **Custom List**. For example, “Speed Quiz” may navigate directly to `QuizScreen` configured in a rapid-fire mode, and “Output Practice” could navigate to a filtered list of phrases focusing on speaking. (These modes correspond to the different learning modes in the spec ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%20%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%8C%E8%8B%A6%E6%89%8B%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%A0%E3%81%91%E3%82%92%E3%83%94%E3%83%83%E3%82%AF%E3%82%A2%E3%83%83%E3%83%97%E3%81%97%E3%80%81%E7%8B%AC%E8%87%AA%E3%83%AA%E3%82%B9%E3%83%88%E3%82%92%E4%BD%9C%E6%88%90%20%E2%86%92%20%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%AF%E3%82%A4%E3%82%BA%E3%82%92%E8%87%AA%E7%94%B1%E3%81%AB%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%A6%E5%86%8D%E5%AD%A6%E7%BF%92)) )  
  The HomeScreen thus serves as a dashboard or menu. It will likely fetch the list of lessons from the content (via `contentService` or context) and render them.

- **src/screens/LessonDetailScreen.tsx**: After choosing a lesson, this screen shows details of that lesson, specifically the list of **Mini-Lessons** (subsections) and their contents. For example, if the lesson is "Greetings", mini-lessons might be "Morning Greetings", "Evening Greetings", etc. ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%20%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%8C%E8%8B%A6%E6%89%8B%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%A0%E3%81%91%E3%82%92%E3%83%94%E3%83%83%E3%82%AF%E3%82%A2%E3%83%83%E3%83%97%E3%81%97%E3%80%81%E7%8B%AC%E8%87%AA%E3%83%AA%E3%82%B9%E3%83%88%E3%82%92%E4%BD%9C%E6%88%90%20%E2%86%92%20%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%AF%E3%82%A4%E3%82%BA%E3%82%92%E8%87%AA%E7%94%B1%E3%81%AB%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%A6%E5%86%8D%E5%AD%A6%E7%BF%92))  Each mini-lesson entry will show its title and maybe a completion status (if phrases are done). This screen uses the lesson ID passed via navigation params to load relevant mini-lesson data (from context or service). From here, the user can select a mini-lesson to start learning, which navigates to the `PhrasePracticeScreen`. A progress bar can indicate lesson completion overall ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=2.%20%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E8%A9%B3%E7%B4%B0%E7%94%BB%E9%9D%A2%20,%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E5%AD%A6%E7%BF%92%E7%94%BB%E9%9D%A2%EF%BC%88%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%EF%BC%89))  which is updated via ProgressContext.

- **src/screens/PhrasePracticeScreen.tsx**: This is the core learning screen for phrases, handling both **Input** and **Output** learning for each phrase. According to the design, it should have two tabs or modes ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=3.%20%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E5%AD%A6%E7%BF%92%E7%94%BB%E9%9D%A2%EF%BC%88%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%EF%BC%89%20,%E6%AC%A1%E3%81%AE%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%B8%E3%80%81%E3%81%BE%E3%81%9F%E3%81%AF%E3%82%AF%E3%82%A4%E3%82%BA%E3%81%B8%E9%80%B2%E3%82%80%E3%83%9C%E3%82%BF%E3%83%B3%204.%20%E3%82%AF%E3%82%A4%E3%82%BA%E7%94%BB%E9%9D%A2)) 
  - **Input Tab**: Displays the phrase in Japanese (with kanji/kana and **furigana** readings), the translation in the user’s language (e.g. English) ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E5%8D%98%E8%AA%9E%E3%83%BB%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E8%A1%A8%E7%A4%BA%20,%E8%BE%9E%E6%9B%B8%E5%8F%82%E7%85%A7%E3%83%BB%E9%96%A2%E9%80%A3%E8%AA%9E%E3%83%AA%E3%83%B3%E3%82%AF))  and an example sentence with translation ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=2.%20%E4%BE%8B%E6%96%87%E6%8F%90%E7%A4%BA%20,%E5%90%8C%E3%81%98%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E5%86%85%E3%81%AE%E9%96%A2%E9%80%A3%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%82%84%E9%A1%9E%E7%BE%A9%E8%AA%9E%E3%81%AA%E3%81%A9%E3%81%B8%E9%81%B7%E7%A7%BB))  It also has a play button to play the phrase’s audio ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E5%8D%98%E8%AA%9E%E3%83%BB%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E8%A1%A8%E7%A4%BA%20,%E5%8D%98%E8%AA%9E%E3%81%AE%E5%88%86%E6%9B%B8%EF%BC%88%E5%85%AC%E5%9C%92%EF%BC%9Dpark%20%E3%81%AA%E3%81%A9%EF%BC%89%E3%82%92%E4%BD%B5%E8%A8%98))  This is essentially a view for *recognition and understanding* of the phrase.
  - **Output Tab**: Allows the user to practice speaking the phrase. It shows maybe the phrase in large text (or the example in Japanese, possibly with some words masked depending on task) and a **microphone button** to record the user’s pronunciation ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=3))  Since we are not integrating real speech APIs in a mock, pressing the mic button can simulate recording and then instantly display a dummy feedback score or message (e.g., “Good!” or “Needs improvement”) to imitate the **pronunciation evaluation** feature ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=3))  We will incorporate a simplified version of the output tasks (for example, just a basic repeat-after-me task) for demonstration. The structure is flexible to include different task types (masked repetition, no text, translation from English, etc. ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=2.%20%E5%A4%9A%E6%A7%98%E3%81%AA%E5%87%BA%E9%A1%8C%E5%BD%A2%E5%BC%8F%EF%BC%88%E3%82%BF%E3%82%B9%E3%82%AF%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88%EF%BC%89%20,%E5%8D%98%E8%AA%9E%E3%83%BB%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E7%BD%AE%E3%81%8D%E6%8F%9B%E3%81%88%EF%BC%9A%E4%BE%8B%E6%96%87%E4%B8%AD%E3%81%AE%E5%8D%98%E8%AA%9E%E3%82%92%E4%BB%96%E3%81%AE%E5%8D%98%E8%AA%9E%E3%81%AB%E5%A4%89%E3%81%88%E3%81%A6%E5%BF%9C%E7%94%A8%E7%B7%B4%E7%BF%92))  by utilizing the content definitions and template parameters if needed.
  - Navigation within this screen: The user can navigate to **next/previous phrases** in the mini-lesson and eventually finish the mini-lesson. After finishing all phrases, a button will lead to the quiz (navigating to `QuizScreen`) ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%AF%E3%82%A4%E3%82%BA%E7%94%BB%E9%9D%A2))   
  Implementation-wise, we might use a **top tab navigator** or segmented control inside this screen to toggle between Input and Output views for the current phrase (ensuring a smooth UX as described). Both tabs can be part of one screen component or separate child components.

- **src/screens/QuizScreen.tsx**: Presents a series of quiz questions to review or test the learned content. The quiz format is multiple-choice (4–5 options) ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E3%82%AF%E3%82%A4%E3%82%BA%E5%BD%A2%E5%BC%8F%E3%81%AE%E5%A4%9A%E6%A7%98%E5%8C%96%20,%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%AA%E3%82%B9%E3%83%88%E3%81%AB%E7%99%BB%E9%8C%B2%E3%81%97%E3%81%9F%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%A0%E3%81%91%E3%82%92%E5%87%BA%E9%A1%8C%203.%20%E3%82%AF%E3%82%A4%E3%82%BA%E7%B5%90%E6%9E%9C%E3%81%AE%E3%83%95%E3%82%A3%E3%83%BC%E3%83%89%E3%83%90%E3%83%83%E3%82%AF))  This screen will be used in two scenarios:
  1. **Lesson Review Quiz**: triggered at the end of a lesson’s mini-lessons (a comprehensive quiz on phrases from that lesson) ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%20%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%8C%E8%8B%A6%E6%89%8B%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%A0%E3%81%91%E3%82%92%E3%83%94%E3%83%83%E3%82%AF%E3%82%A2%E3%83%83%E3%83%97%E3%81%97%E3%80%81%E7%8B%AC%E8%87%AA%E3%83%AA%E3%82%B9%E3%83%88%E3%82%92%E4%BD%9C%E6%88%90%20%E2%86%92%20%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%AF%E3%82%A4%E3%82%BA%E3%82%92%E8%87%AA%E7%94%B1%E3%81%AB%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%A6%E5%86%8D%E5%AD%A6%E7%BF%92))  ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=2.%20%E5%AE%9F%E6%96%BD%E3%82%BF%E3%82%A4%E3%83%9F%E3%83%B3%E3%82%B0%E3%81%AE%E6%9F%94%E8%BB%9F%E6%80%A7%20,%E5%AD%A6%E7%BF%92%E5%B1%A5%E6%AD%B4%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%84%E3%81%A6%E5%BE%A9%E7%BF%92%E3%82%92%E8%87%AA%E5%8B%95%E6%8F%90%E6%A1%88)) 
  2. **Speed Quiz Mode**: triggered from Home for rapid-fire practice of random phrases ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=%E7%89%B9%E5%AE%9A%E3%81%AE%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%EF%BC%88%E4%BE%8B%EF%BC%9A%E3%81%82%E3%81%84%E3%81%95%E3%81%A4%EF%BC%89%E3%82%92%E9%81%B8%E6%8A%9E%20%E2%86%92%20%E5%90%84%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%AE%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%81%A8%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%20%E2%86%92%20%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E7%B5%82%E4%BA%86%E6%99%82%E3%81%AB%E3%81%BE%E3%81%A8%E3%82%81%E3%82%AF%E3%82%A4%E3%82%BA,%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E5%BC%B7%E5%8C%96%E3%82%B3%E3%83%BC%E3%82%B9%20%E7%99%BA%E8%A9%B1%E7%B7%B4%E7%BF%92%E5%BF%85%E9%A0%88%E3%81%AE%E4%BC%9A%E8%A9%B1%E6%96%87%E3%82%92%E4%B8%AD%E5%BF%83%E3%81%AB%E6%8A%BD%E5%87%BA%20%E2%86%92%20%E3%83%9E%E3%82%B9%E3%82%AD%E3%83%B3%E3%82%B0%E5%BE%A9%E5%94%B1%E3%82%84%E8%8B%B1%E8%AA%9E%E6%96%87%E3%81%8B%E3%82%89%E3%81%AE%E7%BF%BB%E8%A8%B3%E7%99%BA%E8%A9%B1%E3%81%AA%E3%81%A9%E3%80%81%E9%9F%B3%E5%A3%B0%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E3%81%AE%E3%81%BF%E3%82%92%E9%80%A3%E7%B6%9A%E7%9A%84%E3%81%AB%E5%AE%9F%E6%96%BD))   
  The screen will receive a set of questions (either generated by `quizService` based on the lesson’s phrases, or a random selection). Each question will display a prompt (e.g., a Japanese phrase or an English meaning) and multiple choices. The user selects an answer:
   - Immediate feedback is given (correct/incorrect) ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E5%AD%A6%E7%BF%92%E5%B1%A5%E6%AD%B4%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%84%E3%81%A6%E5%BE%A9%E7%BF%92%E3%82%92%E8%87%AA%E5%8B%95%E6%8F%90%E6%A1%88)) by highlighting the right answer and maybe showing a short explanation or playing the correct phrase’s audio ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=3.%20%E3%82%AF%E3%82%A4%E3%82%BA%E7%B5%90%E6%9E%9C%E3%81%AE%E3%83%95%E3%82%A3%E3%83%BC%E3%83%89%E3%83%90%E3%83%83%E3%82%AF%20,%E5%AD%A6%E7%BF%92%E5%B1%A5%E6%AD%B4%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%84%E3%81%A6%E5%BE%A9%E7%BF%92%E3%82%92%E8%87%AA%E5%8B%95%E6%8F%90%E6%A1%88)) 
   - A "Next" button (or automatic advance in speed mode) goes to the next question.
  After the last question, the quiz ends and the user might see a summary score and can return to Home or the lesson list.  
  This component will utilize the `ProgressContext` to update the user’s learning history (e.g., mark phrases as mastered or record quiz performance). However, since it's a mock, we might simply log results or update in-memory state. No persistent server calls are made.

- **src/screens/CustomListScreen.tsx** (Optional/Advanced): This screen would allow the user to manage a custom list of favorite or difficult phrases, as hinted by the original “オリジナルリスト” feature ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%20%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%8C%E8%8B%A6%E6%89%8B%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%A0%E3%81%91%E3%82%92%E3%83%94%E3%83%83%E3%82%AF%E3%82%A2%E3%83%83%E3%83%97%E3%81%97%E3%80%81%E7%8B%AC%E8%87%AA%E3%83%AA%E3%82%B9%E3%83%88%E3%82%92%E4%BD%9C%E6%88%90%20%E2%86%92%20%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%AF%E3%82%A4%E3%82%BA%E3%82%92%E8%87%AA%E7%94%B1%E3%81%AB%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%A6%E5%86%8D%E5%AD%A6%E7%BF%92))  ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1,%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%8C%E3%80%8C%E3%81%A9%E3%81%86%E3%81%97%E3%81%A6%E3%82%82%E8%A6%9A%E3%81%88%E3%82%89%E3%82%8C%E3%81%AA%E3%81%84%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%80%8D%E3%82%92%E3%81%8A%E6%B0%97%E3%81%AB%E5%85%A5%E3%82%8A%E3%83%AA%E3%82%B9%E3%83%88%E3%81%B8%E7%99%BB%E9%8C%B2%E3%81%97%E3%80%81%E5%BE%8C%E3%81%A7%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E3%82%92%E4%BD%9C%E6%88%90%E3%81%97%E3%81%A6%E9%87%8D%E7%82%B9%E7%9A%84%E3%81%AB%E5%AD%A6%E7%BF%92))  Here a user could review the phrases they marked and initiate a mini-lesson or quiz just for those. In our initial mock, we might not fully implement this, but we design the architecture to accommodate it. For now, we can stub this screen to show a list of phrases stored in ProgressContext (favorites) and perhaps allow starting a practice or quiz for them, reusing `PhrasePracticeScreen` or `QuizScreen` with filtered data.

- **src/components/PhraseCard.tsx**: A reusable component to display a phrase’s information in a card or list item format. It might show the Japanese text with furigana, the translation, and have an icon/button to play audio. This can be used in the PhrasePracticeScreen (input tab) and also in lists (maybe to show phrase previews in the lesson detail or custom list). Encapsulating this logic ensures consistency in how phrases are displayed throughout the app.

- **src/components/QuizOption.tsx**: A component for rendering a single quiz option (e.g., a styled button or list item for multiple-choice). It receives the option text and a callback for selection. It can handle styling for normal, selected, or correct/incorrect states (e.g., turn green or red after selection in feedback). This makes the QuizScreen code cleaner and separates UI logic for options.

- **src/components/AudioPlayer.tsx**: This could be a small component or utility hook to handle audio playback using Expo’s AV module. For example, it might wrap `Audio.Sound` from `expo-av` and provide a simple interface like `playSound(soundFileUri)`. In our app, whenever the user taps a sound icon next to a phrase or example sentence, this AudioPlayer is used to play the corresponding file (loaded from **assets/audio**). This fulfills the requirement for native pronunciation audio playback ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E5%8D%98%E8%AA%9E%E3%83%BB%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E8%A1%A8%E7%A4%BA%20,%E5%8D%98%E8%AA%9E%E3%81%AE%E5%88%86%E6%9B%B8%EF%BC%88%E5%85%AC%E5%9C%92%EF%BC%9Dpark%20%E3%81%AA%E3%81%A9%EF%BC%89%E3%82%92%E4%BD%B5%E8%A8%98))  The component could also manage loading/unloading audio to avoid memory leaks (as per Expo docs).

- **src/components/MicButton.tsx**: A component for the microphone button used in output practice. It shows a mic icon and possibly an animation or visual indicator when "recording". In the mock, pressing it will trigger the speechService to get a dummy result. We abstract it as a component to easily manage the press handling and any permissions (if we were to use real microphone via expo-av or expo-speech, though in the mock we skip actual recording). This separation allows us to later integrate real voice recording logic without changing the UI.

- **src/context/ContentContext.tsx**: Provides the content data (lessons, phrases, etc.) to the app via React Context. On app load, we can parse or import `content.json` and store it in this context state. Components can then access `contentContext.lessons`, `contentContext.phrases` etc. For example, `HomeScreen` can consume `ContentContext` to get all lessons to display. This approach ensures we load the JSON once and reuse it. (Since the content is static and fairly small, we could also simply import JSON directly in each module, but a context or centralized service makes future scalability easier – e.g., if content could be updated or filtered by user settings.)

- **src/context/ProgressContext.tsx**: Manages user-specific state such as:
  - Completed lessons/mini-lessons (for showing progress bars ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=2.%20%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E8%A9%B3%E7%B4%B0%E7%94%BB%E9%9D%A2%20,%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E5%AD%A6%E7%BF%92%E7%94%BB%E9%9D%A2%EF%BC%88%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%EF%BC%89)) .
  - Favorited phrases or custom list IDs (for the original list feature).
  - Perhaps last quiz scores or other metrics.  
  This context uses React’s Context API and possibly `useReducer` to handle updates (e.g., an action for "MARK_PHRASE_COMPLETED" or "TOGGLE_FAVORITE"). By lifting this state globally, multiple screens can reflect updates. For example, when the user finishes a quiz, the QuizScreen can dispatch an action to mark those phrases as learned, and the HomeScreen progress indicators update accordingly. In a real app, this might be saved to a database or persistent storage ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=))  but for the mock we can persist to AsyncStorage or just memory.

- **src/services/contentService.ts**: Contains functions that simulate API calls to fetch content. For instance:
  - `getAllLessons(): Promise<Lesson[]>` – returns the list of lessons (by reading from content context or JSON).
  - `getLesson(lessonId): Promise<LessonDetail>` – returns a specific lesson’s details, including mini-lessons and phrases.
  - `getPhrases(miniLessonId): Promise<Phrase[]>` – returns phrases for a given mini-lesson.  
  These functions mimic asynchronous behavior (using `Promise` or `async/await`, possibly with a `setTimeout` to simulate network latency). This way, the UI code can *await* data as if it were calling a real API. The data comes from local JSON, fulfilling the **mock API** requirement (all data is local, no real network) but preserving the structure of an API layer in the code.

- **src/services/quizService.ts**: Contains logic for generating and evaluating quizzes. Functions could include:
  - `generateQuizForLesson(lessonId): QuizQuestion[]` – create a list of quiz questions based on all phrases in a lesson. Each question could ask the meaning of a Japanese phrase or ask to pick the correct phrase given a meaning, etc. (The content JSON might include pre-defined quiz items ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E5%AD%A6%E7%BF%92%E3%82%BF%E3%82%B9%E3%82%AF%EF%BC%88%E6%8F%90%E7%A4%BA%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%EF%BC%9A%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E8%A1%A8%E7%A4%BA%E3%81%AE%E6%9C%89%E7%84%A1%E3%80%81%E9%9F%B3%E5%A3%B0%E8%A1%A8%E7%A4%BA%E3%81%AE%E6%9C%89%E7%84%A1%E3%80%81%E3%83%9E%E3%82%B9%E3%82%AD%E3%83%B3%E3%82%B0%E7%AE%87%E6%89%80%E3%81%AA%E3%81%A9%EF%BC%89))  which we can use directly. If present, we simply fetch those. Otherwise, we can generate basic "what does X mean?" questions from phrase data.)
  - `generateSpeedQuiz(): QuizQuestion[]` – create a random mix of questions covering various phrases (or use a subset of content based on user’s progress).
  - `checkAnswer(question: QuizQuestion, chosenOption: string): boolean` – returns true/false or a score, to indicate if the answer was correct. Could also return an explanation text or the correct answer for feedback.  
  This service abstracts quiz logic so the QuizScreen remains focused on rendering. In the mock, the quiz logic can be simple (exact match of translation, etc.), but it’s structured for easy enhancement (like adding context-based or usage questions as described in the spec ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%AA%E3%82%B9%E3%83%88%E3%81%AB%E7%99%BB%E9%8C%B2%E3%81%97%E3%81%9F%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%A0%E3%81%91%E3%82%92%E5%87%BA%E9%A1%8C%203.%20%E3%82%AF%E3%82%A4%E3%82%BA%E7%B5%90%E6%9E%9C%E3%81%AE%E3%83%95%E3%82%A3%E3%83%BC%E3%83%89%E3%83%90%E3%83%83%E3%82%AF)) .

- **src/services/speechService.ts**: Simulates the **speech recognition and pronunciation scoring**. In a real app, pressing the mic would involve calling cloud APIs (Google, Azure, etc.) to get speech-to-text and a score ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=%2A%20%E9%9F%B3%E5%A3%B0%E8%AA%8D%E8%AD%98%E3%83%BB%E7%99%BA%E9%9F%B3%E8%A9%95%E4%BE%A1%EF%BC%9A%20Google%20Cloud%20Speech,Azure%20Cognitive%20Services%E3%80%81Amazon%20Transcribe%E3%81%AA%E3%81%A9%E3%81%AE%E5%88%A9%E7%94%A8%E3%82%92%E6%83%B3%E5%AE%9A%E3%80%82%20API%E3%81%8B%E3%82%89%E5%8F%97%E3%81%91%E5%8F%96%E3%81%A3%E3%81%9F%E6%96%87%E5%AD%97%E8%B5%B7%E3%81%93%E3%81%97%E7%B5%90%E6%9E%9C%E3%81%A8%E6%AD%A3%E8%A7%A3%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%82%92%E6%AF%94%E8%BC%83%E3%81%97%E3%80%81%E3%82%A4%E3%83%B3%E3%83%88%E3%83%8D%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E8%A9%95%E4%BE%A1%E3%82%84%E9%A1%9E%E4%BC%BC%E5%BA%A6%E3%82%B9%E3%82%B3%E3%82%A2%E3%82%92%E7%AE%97%E5%87%BA%E3%80%82))  Here we implement a placeholder:
  - `evaluatePronunciation(expectedPhrase: Phrase, userAudio: Blob | null): { score: number, feedback: string }` – since we won’t actually record audio in the mock, `userAudio` might be null or a dummy input. We can simply return a random score or a fixed value (for example, always “score: 80/100, feedback: ‘Good try!’”). Alternatively, we could compare a hardcoded “expected answer” string with a pretend "recognized text" (for demo purposes) to decide if it matches.  
  The key is to **mimic the behavior**: the user taps mic, we wait a moment, then update the UI with some evaluation result, fulfilling the app’s core output feature in principle ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E7%99%BA%E9%9F%B3%E5%85%A5%E5%8A%9B%E3%83%BB%E8%A9%95%E4%BE%A1%20,%E6%96%87%E5%AD%97%E3%81%AE%E3%81%BF%E6%8F%90%E7%A4%BA%EF%BC%9A%E9%9F%B3%E5%A3%B0%E3%81%AA%E3%81%97%E3%81%A7%E7%99%BA%E9%9F%B3))  This service allows us to later integrate real APIs with minimal changes, since the rest of the app just calls `speechService.evaluatePronunciation()`.

- **src/types/content.types.ts**: Defines TypeScript interfaces/types for the content data model:
  - `interface Phrase { id: string; jpText: string; reading: string; translations: Record<string,string>; audio: string; exampleSentence?: string; exampleTranslation?: string; words?: Word[]; }` – representing a vocabulary/phrase item. This matches the fields given in the requirement’s JSON example ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%7D%2C))  ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E5%85%AC%E5%9C%92)) (id, Japanese text, reading, translations in multiple languages, audio path, plus optional example sentence with word-by-word meanings).
  - `interface MiniLesson { id: string; title: string; phraseIds: string[]; }` – a grouping of phrases (5–10) as per spec ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E8%A4%87%E6%95%B0%E3%81%AE%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E3%82%92%E6%9D%9F%E3%81%AD%E3%81%9F%E3%83%86%E3%83%BC%E3%83%9E%EF%BC%88%E4%BE%8B%EF%BC%9A%E5%9F%BA%E6%9C%AC%E3%81%AE%E6%8C%A8%E6%8B%B6%E3%80%81%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9%E3%83%A1%E3%83%BC%E3%83%AB%E8%A1%A8%E7%8F%BE%E3%81%AA%E3%81%A9%EF%BC%89))  It contains a title and list of phrase IDs that belong to it. (We might also include a field for description or category.)
  - `interface Lesson { id: string; title: string; description?: string; miniLessons: MiniLesson[]; }` – representing a full lesson which can contain multiple mini-lessons ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=2.%20%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%EF%BC%88MiniLesson%EF%BC%89%EF%BC%9A%20,%E8%A4%87%E6%95%B0%E3%81%AE%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E3%82%92%E6%9D%9F%E3%81%AD%E3%81%9F%E3%83%86%E3%83%BC%E3%83%9E%EF%BC%88%E4%BE%8B%EF%BC%9A%E5%9F%BA%E6%9C%AC%E3%81%AE%E6%8C%A8%E6%8B%B6%E3%80%81%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9%E3%83%A1%E3%83%BC%E3%83%AB%E8%A1%A8%E7%8F%BE%E3%81%AA%E3%81%A9%EF%BC%89))  E.g., Lesson "Greetings" contains mini-lessons "Morning Greetings", "Evening Greetings".
  - `interface QuizQuestion { question: string; options: string[]; correctAnswer: string; explanation?: string; }` – a generic quiz question structure. For a meaning quiz, `question` might be a Japanese phrase text and options are possible English meanings (including the correct one). Alternatively, for a usage quiz, question could be a sentence with a blank and options to fill it. The design allows both basic meaning quizzes and contextual quizzes ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%AA%E3%82%B9%E3%83%88%E3%81%AB%E7%99%BB%E9%8C%B2%E3%81%97%E3%81%9F%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%A0%E3%81%91%E3%82%92%E5%87%BA%E9%A1%8C%203.%20%E3%82%AF%E3%82%A4%E3%82%BA%E7%B5%90%E6%9E%9C%E3%81%AE%E3%83%95%E3%82%A3%E3%83%BC%E3%83%89%E3%83%90%E3%83%83%E3%82%AF))  though our mock will likely implement the basic type first.  
  Having these types ensures our components and services use data consistently and catch errors at compile time. We might also define types for the context values (e.g., `type ContentContextValue = { lessons: Lesson[]; phrasesById: Record<string,Phrase>; ... }`).

- **src/navigation/types.ts**: Contains React Navigation type definitions for route parameters. For example:
  ```ts
  type RootStackParamList = {
    Home: undefined;
    LessonDetail: { lessonId: string };
    PhrasePractice: { miniLessonId: string; startPhraseId?: string };
    Quiz: { mode: 'lesson' | 'speed' | 'custom'; lessonId?: string };
  };
  ``` 
  This ensures that when we navigate, e.g., `navigation.navigate('LessonDetail', { lessonId: 'lesson_greetings' })`, the params are type-checked. It’s a best practice with React Navigation and TS ([Type checking with TypeScript - React Navigation](https://reactnavigation.org/docs/typescript/#:~:text=Type%20checking%20with%20TypeScript%20,various%20other%20APIs%20using%20TypeScript)) to avoid runtime errors.

- **tsconfig.json**: We will enable strict typing (`"strict": true`) and include settings to support React Native and asset imports. For instance, `"resolveJsonModule": true` allows importing JSON files as modules (used for `content.json`). We may also define custom type declarations for image/audio imports so TypeScript knows how to handle `require('audio/ohayou.mp3')`. This configuration ensures we fully leverage TypeScript’s safety in the Expo environment.

- **Utilities (utils/**)**: Any general helper that doesn't logically fit elsewhere. For example, `audioUtils.ts` might have a function to format text-to-speech or to request microphone permissions (if we were doing real recording), or `formatUtils.ts` might format furigana in a string. We keep these separate to avoid cluttering components with low-level details.

This breakdown ensures each file has a single, well-defined purpose (Single Responsibility Principle). UI components focus on rendering, services handle data logic, contexts manage state, and navigation handles app flow. Such decoupling makes the app easier to test and extend (even though tests are not required per the conditions).

## 3. Implementation Approach

With the structure in mind, we detail how we will implement key aspects of the app, adhering to best practices:

### 3.1 State Management Approach

We will use **React Context API with Hooks** for state management, which is sufficient for this app’s needs. The app’s state can be divided mainly into **content data** (static) and **user progress** (dynamic):

- **Content Data**: The lesson and phrase content is largely static and can be loaded from JSON. We do not expect frequent updates to this data at runtime (aside from filtering or selecting subsets). Therefore, we can load it once and store it in `ContentContext`. This context is read-only after initialization (no complex state logic needed beyond maybe a setter if we allow dynamic content updates). Since the content is hierarchical (Lesson > MiniLesson > Phrase) ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%EF%BC%88Phrase%EF%BC%89%EF%BC%9A%20,%E8%A4%87%E6%95%B0%E3%81%AE%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E3%82%92%E6%9D%9F%E3%81%AD%E3%81%9F%E3%83%86%E3%83%BC%E3%83%9E%EF%BC%88%E4%BE%8B%EF%BC%9A%E5%9F%BA%E6%9C%AC%E3%81%AE%E6%8C%A8%E6%8B%B6%E3%80%81%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9%E3%83%A1%E3%83%BC%E3%83%AB%E8%A1%A8%E7%8F%BE%E3%81%AA%E3%81%A9%EF%BC%89))  we might preprocess it (e.g., build a map of phraseId to Phrase object for quick lookup, and attach phrases to each mini-lesson) when initializing the context.

- **User Progress & Settings**: This includes which lessons are completed, which phrases the user favorited or needs to review, and possibly UI settings (like chosen translation language, though for simplicity we assume English). This state will change as the user interacts:
  - Mark a mini-lesson or lesson complete after finishing.
  - Add or remove a phrase from favorites (original list).
  - Record quiz results or high scores (if we want to show improvement).  
  Context + `useReducer` is a lightweight solution to manage these. For example, `ProgressContext` could use:
  ```ts
  type ProgressAction = 
    | { type: 'COMPLETE_PHRASE'; phraseId: string }
    | { type: 'COMPLETE_LESSON'; lessonId: string }
    | { type: 'TOGGLE_FAVORITE'; phraseId: string };
  ``` 
  and maintain state like `{ completedPhrases: Set<string>; completedLessons: Set<string>; favoritePhrases: Set<string>; }`.  
  Dispatching actions on quiz completion or when the user presses a Favorite button in the UI will update this context, causing subscribed components (like progress bars on LessonDetail or icons on phrases) to re-render with updated info.

We choose Context API over heavier solutions like Redux or Recoil for now because:
- **Complexity**: The app’s state is not extremely complex; a few slices of state can be handled with context and reducers. Redux would add extra boilerplate (actions, reducers, store configuration) without a clear benefit at this scale. Recoil is another option (simpler global state management), but introducing another dependency for global state is unnecessary given the manageable state size.
- **Scope**: Since there’s no requirement for advanced features like time-travel debugging or very elaborate state transformations, Context with Hooks suffices. If the app were to grow significantly or become multi-module with many developers, adopting Redux or another state library could be reconsidered. In this mock design, we prioritize simplicity and clarity.

Using React Context is also in line with best practices for many Expo/React Native apps when the state is not too large. It avoids prop-drilling (e.g., passing content data down multiple layers) by providing data at a high level. Additionally, by defining clear context provider components (`ContentProvider`, `ProgressProvider`), we encapsulate how data is fetched and updated, keeping components unaware of the underlying mechanism (could swap out to Redux in future if needed without major changes to components).

**Local Persistence**: While not strictly required by the prompt, a best practice for a real app would be to persist some state (like progress or custom lists) so it’s not lost on app restart. We could use **AsyncStorage** (via `@react-native-async-storage/async-storage`) or Expo’s **SecureStore** for this. For example, when `ProgressContext` updates, we could save the new progress to AsyncStorage. On app load, we initialize progress state from storage if available. This ensures the app behaves realistically (though in a mock environment this can be optional).

### 3.2 UI Library and Styling

We will use **React Native Paper** as our UI component library (Material Design). This provides a set of ready-to-use, cross-platform components that ensure the app looks professional out-of-the-box. The reasons for choosing React Native Paper include:
- It offers components like **Appbar, Card, Button, List, Dialog, Tabs** etc., which we can utilize for our screens. For example, we can use Paper’s `Appbar` for screen headers and navigation, `List.Item` or `Card` for listing lessons and phrases (with icons for audio), and `Button` for quiz options (styled as contained or outlined buttons).
- It supports theming, so we can define a theme (colors, fonts) consistent with a learning app vibe. We can use a light theme with maybe an accent color for correctness indication (e.g., green for correct, red for incorrect answers in quiz).
- Paper is well-tested across iOS and Android, so it handles things like Ripple effects on Android and appropriate touch feedback on iOS automatically.

Alternative UI libraries could be **Native Base** or **React Native Elements**. We choose RN Paper for its Material design which is intuitive for both Android and iOS users and its seamless integration with Expo. It will help implement our screens faster:
  - The tab view for Input/Output can use Paper’s `TabView` or we can use React Navigation’s MaterialTopTabs which align with Material styling (Paper would ensure the styling is proper).
  - The progress bar on LessonDetail could be implemented with Paper’s `ProgressBar` component to visually show completion ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=2.%20%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E8%A9%B3%E7%B4%B0%E7%94%BB%E9%9D%A2%20,%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E5%AD%A6%E7%BF%92%E7%94%BB%E9%9D%A2%EF%BC%88%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%EF%BC%89)) 
  - Forms or dialogs (if any, e.g., confirming reset or such) can use Paper’s Modal/Dialog.
  
For layout and styling, we will use **Flexbox** and StyleSheet from React Native, possibly augmented by utility styles or Paper’s theming. We ensure to use responsive units or percentages where appropriate so the app looks good on various screen sizes. Expo provides a consistent environment, and we can test on both platforms easily with Expo Go.

We also keep accessibility in mind: using readable font sizes, sufficient contrast, and adding accessibility labels for buttons (especially the mic and audio buttons, so screen readers can identify them). React Native Paper supports accessibility by default in many components.

### 3.3 Mock API and Data Handling

All external data interactions are replaced with **mock implementations** within the app:

- **Content Retrieval**: In a real scenario, content might be fetched from a server or database ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=))  but here we bundle it. The `contentService` functions simply read from local JSON (synchronously or via a short asynchronous call). For example, `getAllLessons()` might return the list of lessons by reading from `content.json` (which contains all lessons, miniLessons, and phrases). By using a service function, the rest of the app can call it as if it were an API. We can simulate network delay using a `setTimeout` of a few hundred milliseconds to mimic loading. This will make the UI show loading indicators (we will implement ActivityIndicator from RN Paper or similar while data is "loading") which is a good practice.

- **Voice Recognition & Pronunciation**: The README suggests using cloud APIs for speech-to-text and scoring pronunciation ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=%2A%20%E9%9F%B3%E5%A3%B0%E8%AA%8D%E8%AD%98%E3%83%BB%E7%99%BA%E9%9F%B3%E8%A9%95%E4%BE%A1%EF%BC%9A%20Google%20Cloud%20Speech,Azure%20Cognitive%20Services%E3%80%81Amazon%20Transcribe%E3%81%AA%E3%81%A9%E3%81%AE%E5%88%A9%E7%94%A8%E3%82%92%E6%83%B3%E5%AE%9A%E3%80%82%20API%E3%81%8B%E3%82%89%E5%8F%97%E3%81%91%E5%8F%96%E3%81%A3%E3%81%9F%E6%96%87%E5%AD%97%E8%B5%B7%E3%81%93%E3%81%97%E7%B5%90%E6%9E%9C%E3%81%A8%E6%AD%A3%E8%A7%A3%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%82%92%E6%AF%94%E8%BC%83%E3%81%97%E3%80%81%E3%82%A4%E3%83%B3%E3%83%88%E3%83%8D%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E8%A9%95%E4%BE%A1%E3%82%84%E9%A1%9E%E4%BC%BC%E5%BA%A6%E3%82%B9%E3%82%B3%E3%82%A2%E3%82%92%E7%AE%97%E5%87%BA%E3%80%82))  but our condition is to avoid actual API calls. So, `speechService.evaluatePronunciation()` will fabricate a result. Implementation idea: When the user presses the mic (MicButton component triggers evaluation), we can:
  - Show a loading indicator or waveform animation for 1-2 seconds (simulating “listening” and processing).
  - Then return a result object, e.g., `{ score: 0.8, feedback: "Great pronunciation!" }` or maybe a simple pass/fail. We might vary the feedback randomly or based on the phrase to keep it interesting (e.g., for certain phrases return a "needs practice" to simulate difficulty).
  - The PhrasePracticeScreen will display this feedback. Perhaps we use a Snackbar or a colored text indicator.  
  This fulfills the main goal of providing **real-time pronunciation evaluation feedback** in concept ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=3))  without actual ML backend. We will document clearly that this is a mock/stub.

- **Audio Playback**: Using Expo’s Audio API (from `expo-av`) to play local files. This isn’t an external web API, it’s part of the app’s capabilities, so it’s allowed. The `AudioPlayer` component or `audioUtils` will load the file (which could be referenced by require or URI from assets) and play it. We ensure the audio files listed in `content.json` (like `"audio": "audio/ikimasu.mp3"`) are packaged under assets/audio. Expo will bundle those in the binary so they can be accessed offline.  
  We might provide a fallback if audio is missing (like if a file isn't found, catch the error and perhaps show an alert that audio is not available in the mock). But ideally, we include at least a few audio files to demonstrate the feature.

- **Quiz Logic**: No calls to any external service; quiz content is derived from our static data or the JSON. The `quizService` might either use predefined quiz entries from `content.json` (the spec mentioned each phrase could have associated quiz questions ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E5%AD%A6%E7%BF%92%E3%82%BF%E3%82%B9%E3%82%AF%EF%BC%88%E6%8F%90%E7%A4%BA%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%EF%BC%9A%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E8%A1%A8%E7%A4%BA%E3%81%AE%E6%9C%89%E7%84%A1%E3%80%81%E9%9F%B3%E5%A3%B0%E8%A1%A8%E7%A4%BA%E3%81%AE%E6%9C%89%E7%84%A1%E3%80%81%E3%83%9E%E3%82%B9%E3%82%AD%E3%83%B3%E3%82%B0%E7%AE%87%E6%89%80%E3%81%AA%E3%81%A9%EF%BC%89))  or generate them. Either way, all the data remains inside the app. When the user answers, we immediately show feedback. If we want to simulate a backend evaluation (for example, in some apps quizzes might be submitted to a server for tracking), we can skip that and handle scoring locally. After each answer, we can update ProgressContext (e.g., track that this phrase was answered correctly, which could be used for future AI-driven recommendations as speculated in the doc ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E5%AD%A6%E7%BF%92%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E9%AB%98%E5%BA%A6%E5%8C%96%20,%E5%BA%83%E5%91%8A%E3%83%A2%E3%83%87%E3%83%AB%E3%81%A8%E3%81%AE%E3%83%90%E3%83%A9%E3%83%B3%E3%82%B9%E3%82%92%E8%80%83%E6%85%AE%E3%81%97%E3%80%81%E5%AD%A6%E7%BF%92%E4%BD%93%E9%A8%93%E3%82%92%E6%90%8D%E3%81%AA%E3%82%8F%E3%81%AA%E3%81%84%E5%BD%A2%E3%81%A7%E3%81%AE%E5%B0%8E%E5%85%A5%E3%82%92%E6%A4%9C%E8%A8%8E)) – though we won't implement AI in the mock, we keep data such that it could be analyzed later).

- **No Network Calls**: We will ensure that any module that in a real app would call `fetch()` or third-party SDKs (like Google Cloud) is either removed or replaced with dummy functions. This not only fits the requirement (all API calls mocked) but also means the app is fully offline-capable. The content JSON and audio being bundled means users can use the app without internet, except obviously we cannot truly do speech recognition offline. But since it's mocked, that also works offline.

- **Data Storage**: As mentioned, everything is stored in memory or device storage. In our design, `content.json` is our "content database" and `ProgressContext` (with optional AsyncStorage persistence) is our "user database". We are effectively following the requirement to keep **data in-app** ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%EF%BC%88JSON%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%84%E9%9F%B3%E5%A3%B0%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%EF%BC%89%E3%81%AF%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B8%EF%BC%8BCDN%E3%81%A7%E9%85%8D%E4%BF%A1))  This simplifies development and ensures fast access. If this were a prototype, it allows working on the front-end features without a backend ready.

- **Error Handling**: We will include basic error handling for the mock services. For example, if a lesson ID is not found in content, the service can throw an error or return a rejection. The UI (perhaps in LessonDetailScreen) should handle this gracefully, maybe by showing a "Content not found" message. Similarly, if audio fails to play, catch it and perhaps alert "Audio unavailable." This is part of best practices to handle unexpected issues even in a mock environment.

### 3.4 Navigation Strategy

We will implement navigation using **React Navigation (v6)**, as it’s the de-facto standard for Expo apps and was implicitly expected (the question references React Navigation). Our navigation strategy:

- **Stack Navigation**: We use a Stack Navigator for screen transitions: Home -> LessonDetail -> PhrasePractice -> Quiz. This linear stack fits the flow where each screen drills deeper into the learning process. We will configure header titles for each screen appropriately (e.g., title of the lesson on the LessonDetail screen, phrase or mini-lesson name on the practice screen, etc.). The stack allows the user to press a back button to go to the previous screen (e.g., from Quiz back to Home or back to LessonDetail, depending on how we route it – we might reset to Home after quiz completion to avoid deep stacking too much).

- **Tab Navigation (within PhrasePractice)**: For the Input/Output toggle, we have two approaches:
  1. Use React Navigation’s **Material Top Tabs** nested inside the PhrasePractice route. This means `PhrasePracticeScreen` would actually host a Tab Navigator with two child screens: one for “Input” view and one for “Output” view. These could be separate components (say `PhraseInputScreen` and `PhraseOutputScreen`) that both receive the phrase data. This approach clearly separates the UI for input vs output practice, and React Navigation will handle the swipe or tab click gesture for switching. We can style the tab indicator, etc., and it will resemble the spec’s idea of an **Input/Output tab interface** ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=3.%20%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E5%AD%A6%E7%BF%92%E7%94%BB%E9%9D%A2%EF%BC%88%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%EF%BC%89%20,%E6%AC%A1%E3%81%AE%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%B8%E3%80%81%E3%81%BE%E3%81%9F%E3%81%AF%E3%82%AF%E3%82%A4%E3%82%BA%E3%81%B8%E9%80%B2%E3%82%80%E3%83%9C%E3%82%BF%E3%83%B3%204.%20%E3%82%AF%E3%82%A4%E3%82%BA%E7%94%BB%E9%9D%A2)) 
  2. Alternatively, manage the tab switch with local state and conditionally render in one `PhrasePracticeScreen` component. This is simpler, but we lose out on the nice built-in animations and structure that Navigation provides.  

  We opt for the first approach (nested top tabs) for a more modular design: it follows best practice by not overloading one component with too much logic. It also allows each sub-screen to focus on either input or output UI. React Navigation makes it easy to pass the necessary params (like the current phrase or phrase ID) to these nested screens via route params or a shared context.

- **Passing Data via Navigation**: We use route params to pass identifiers, not large data objects. For example, when navigating to `LessonDetailScreen`, we pass `{ lessonId: 'lesson_greetings' }`. The screen will then look up the lesson details from ContentContext or service. This avoids hitting the nav param size limits and keeps a single source of truth for content (the context). Similarly, for `PhrasePracticeScreen`, we might pass `{ miniLessonId: 'lesson_greetings_1' }` (and that screen will load the list of phrases for that mini-lesson from content) and maybe also the initial phrase index. For `QuizScreen`, we pass mode and perhaps lessonId if it’s a lesson quiz. This way, the `QuizScreen` knows whether to generate questions from a specific lesson or from all content (for speed quiz).

- **Navigation Guards & Conditionals**: In a simple mock, we might not need advanced guards, but we ensure, for instance, that the user cannot start a quiz without content. If a user somehow navigates to QuizScreen without proper params, we handle it by defaulting to a general quiz or redirecting to Home. Also, after completing a lesson’s quiz, we might automatically navigate the user back to Home or show a completion modal with an option to go back.

- **Deep Linking (Future)**: Expo and React Navigation support deep linking. While not required, we can note that our structure could easily map to deep links (like `myapp://lesson/greetings` to open the Greetings lesson). This is a sign of a robust navigation strategy, though for now we focus on basic navigation.

- **Back Button Handling**: On Android, the hardware back button should back-navigate properly. React Navigation handles this by default for stack navigators. We just need to be mindful if we use custom handlers in certain screens (e.g., if editing in CustomListScreen and unsaved, maybe prompt). In our design, nothing requires intercepting the back action specially, so default is fine.

Overall, the navigation design ensures the app flows match the described user experience ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=))  For example, a typical flow: 
1. User starts on HomeScreen, selects "Greetings Lesson" (navigate to LessonDetail).
2. On LessonDetail, selects "Morning Greetings" mini-lesson (navigate to PhrasePractice).
3. On PhrasePractice, after going through phrases in Input/Output, hits "Quiz" (navigate to QuizScreen).
4. Completes quiz, sees results, then returns to Home (either automatically or by Back action).  
This corresponds exactly to the example given in the spec ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=5))  React Navigation will help implement this smoothly.

We will also leverage TypeScript integration with React Navigation for safety (as mentioned earlier, using a typed `RootStackParamList`). This way, navigation calls and route uses (`route.params`) will be checked by the compiler, preventing common errors like missing params.

### 3.5 Data Modeling and TypeScript Usage

TypeScript will be used extensively to model data and catch errors early. Key aspects:

- **Data Models**: We define interfaces for all main entities: Phrase, Lesson, etc. (see **src/types/content.types.ts** above). These are derived from the specification where possible:
  - The **phrase** model includes Japanese text, reading (furigana), translation(s) in multiple languages, audio path, and optionally example sentences ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%7D%2C))  ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E5%85%AC%E5%9C%92))  This allows the input view to display everything needed. 
  - The hierarchy of **Lesson** -> **MiniLesson** -> **Phrase** is represented in our data structures, reflecting the content hierarchy from the doc ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%EF%BC%88Phrase%EF%BC%89%EF%BC%9A%20,%E8%A4%87%E6%95%B0%E3%81%AE%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E3%82%92%E6%9D%9F%E3%81%AD%E3%81%9F%E3%83%86%E3%83%BC%E3%83%9E%EF%BC%88%E4%BE%8B%EF%BC%9A%E5%9F%BA%E6%9C%AC%E3%81%AE%E6%8C%A8%E6%8B%B6%E3%80%81%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9%E3%83%A1%E3%83%BC%E3%83%AB%E8%A1%A8%E7%8F%BE%E3%81%AA%E3%81%A9%EF%BC%89))  By having these clearly defined, we ensure that, for example, a Lesson always contains an array of MiniLessons, each MiniLesson has an array of phrase IDs, and we can easily find the Phrase objects for them.
  - We also define a type for quiz questions that can accommodate the basic multiple-choice format and potentially other formats (the spec hints at both basic meaning quizzes and more applied quizzes ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%AA%E3%82%B9%E3%83%88%E3%81%AB%E7%99%BB%E9%8C%B2%E3%81%97%E3%81%9F%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%A0%E3%81%91%E3%82%92%E5%87%BA%E9%A1%8C%203.%20%E3%82%AF%E3%82%A4%E3%82%BA%E7%B5%90%E6%9E%9C%E3%81%AE%E3%83%95%E3%82%A3%E3%83%BC%E3%83%89%E3%83%90%E3%83%83%E3%82%AF)) . For now, we stick to multiple-choice textual questions for simplicity.

- **Type Safety in Components**: Each screen component will have its props typed (especially the route params from navigation). For example:
  ```ts
  type LessonDetailProps = NativeStackScreenProps<RootStackParamList, 'LessonDetail'>;
  function LessonDetailScreen({ route, navigation }: LessonDetailProps) {
    const { lessonId } = route.params;
    // ...
  }
  ``` 
  This ensures `lessonId` is recognized as a string and required. We’ll also type the dispatch and state in our context using TypeScript Generics (e.g., `React.createContext<ProgressState | undefined>(undefined)` and a Dispatch type for actions).

- **Interfaces for Services**: The functions in our services can also use the data model types. E.g., `function getAllLessons(): Lesson[]` makes it clear what is returned. If we accidentally return the wrong shape, TS will complain. In `quizService.checkAnswer`, we might define it as `function checkAnswer(q: QuizQuestion, answer: string): boolean` which is straightforward, but if we later extend QuizQuestion to have a numeric correctAnswer index, we'd update the function signature accordingly. This tight coupling via types prevents mismatches.

- **Leveraging TS for Mock Data**: Since `content.json` is static, one trick is to write it as a `.ts` file exporting a constant. For example, we could have `content.ts` that does:
  ```ts
  import { Lesson } from './content.types';
  export const content: Lesson[] = [ { id: 'lesson_greetings', title: 'Greetings', miniLessons: [ ... ] }, ... ];
  ``` 
  This way, the content is actually type-checked at build time (ensuring our JSON structure matches the TypeScript interfaces). For large data this isn't practical, so we likely keep JSON and might do runtime validation. But we can still use TS by importing the JSON and casting to our types or using something like `zod` schemas to validate it matches our interface on load.

- **Strict Null Checks**: We will enable strict null checking in TS. This means we handle cases like optional fields or data not found. For instance, if `findPhraseById(id)` might return undefined, our code will force us to handle that (perhaps by throwing an error or showing a message). This is important so we don't run into undefined values at runtime.

- **Enum and Union Types**: For certain fixed values, we use union types. E.g., for quiz mode param we had `'lesson' | 'speed' | 'custom'`. We might also use an enum or union for languages, e.g., allowed keys in `translations` might be `'en' | 'ja' | 'zh'`, etc. The spec mentions multi-language support for translations ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E5%8D%98%E8%AA%9E%E3%83%BB%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E8%A1%A8%E7%A4%BA%20,%E8%BE%9E%E6%9B%B8%E5%8F%82%E7%85%A7%E3%83%BB%E9%96%A2%E9%80%A3%E8%AA%9E%E3%83%AA%E3%83%B3%E3%82%AF))  so we could define a type for language codes and enforce that. In the mock, we likely only use English, but the structure is there.

- **Development Experience**: Using TypeScript in Expo (with VSCode or similar) will give us autocompletion and instant feedback. For example, when rendering a PhraseCard, the props must match the Phrase type, so we can’t accidentally try to access a property that doesn’t exist. This reduces bugs during development of the mock.

By fully embracing TypeScript, we treat the spec’s data contract seriously – effectively the README’s JSON structure is our contract, and TS interfaces are derived from it. This is a best practice to ensure the app and content stay in sync. It will also make future integration easier (e.g., if connecting to a real API later, we can use the same types to decode JSON responses).

### 3.6 Cross-platform Considerations

Since we use Expo/React Native, most code is cross-platform by default. We will ensure:
- UI uses responsive design so it looks good on various screen sizes and both orientations if allowed.
- Use of platform-specific safe areas. Expo provides `SafeAreaView` to avoid notches on iOS. We will wrap top-level screens in SafeAreaView where appropriate (or use Paper’s Provider which can handle some of that).
- Any platform-specific differences in behavior are handled. For example, React Native Paper on Android might use Material default styles (like ripple on buttons) while on iOS it might not show ripple. We accept these native differences as they align with platform expectations.
- Testing on both iOS and Android during development via Expo will be done to catch any issues (e.g., font rendering differences or audio permission prompts – Expo will ask microphone permission on both maybe, which we handle gracefully by requesting permission when mic is first used, though in mock we might skip actual permission since not recording).

No separate code branches for iOS/Android are anticipated, but if needed, RN provides `Platform` module to conditionally handle cases (for instance, file paths or status bar styles). We likely won't need this in our design.

## Conclusion

This detailed design outlines a maintainable Expo + TypeScript implementation for the Japanese Learning App, satisfying all given conditions. We structured the app into clear modules and used Context for state and React Navigation for flow, aligning with the app's specified features. By using local JSON data and simulating APIs, the app can run offline with all content bundled, meeting the requirement of no real API calls and data stored in-app ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%B3%E3%83%B3%E3%83%86%E3%83%B3%E3%83%84%EF%BC%88JSON%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%84%E9%9F%B3%E5%A3%B0%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%EF%BC%89%E3%81%AF%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B8%EF%BC%8BCDN%E3%81%A7%E9%85%8D%E4%BF%A1))  The design accounts for key app features from the README:

- Balanced **Input/Output practice** flow (with an Input tab for content review and an Output tab for speaking practice) ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=3.%20%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E5%AD%A6%E7%BF%92%E7%94%BB%E9%9D%A2%EF%BC%88%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%EF%BC%89%20,%E6%AC%A1%E3%81%AE%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%B8%E3%80%81%E3%81%BE%E3%81%9F%E3%81%AF%E3%82%AF%E3%82%A4%E3%82%BA%E3%81%B8%E9%80%B2%E3%82%80%E3%83%9C%E3%82%BF%E3%83%B3%204.%20%E3%82%AF%E3%82%A4%E3%82%BA%E7%94%BB%E9%9D%A2))  including audio playback and (simulated) pronunciation feedback ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=3)) 
- A flexible **Quiz system** for review, supporting both end-of-lesson quizzes and a speed quiz mode ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%9F%E3%83%8B%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%20%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%8C%E8%8B%A6%E6%89%8B%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%A0%E3%81%91%E3%82%92%E3%83%94%E3%83%83%E3%82%AF%E3%82%A2%E3%83%83%E3%83%97%E3%81%97%E3%80%81%E7%8B%AC%E8%87%AA%E3%83%AA%E3%82%B9%E3%83%88%E3%82%92%E4%BD%9C%E6%88%90%20%E2%86%92%20%E3%82%A4%E3%83%B3%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E3%83%BB%E3%82%AF%E3%82%A4%E3%82%BA%E3%82%92%E8%87%AA%E7%94%B1%E3%81%AB%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%81%A6%E5%86%8D%E5%AD%A6%E7%BF%92))  ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E3%82%AF%E3%82%A4%E3%82%BA%E5%BD%A2%E5%BC%8F%E3%81%AE%E5%A4%9A%E6%A7%98%E5%8C%96%20,%E3%82%AA%E3%83%AA%E3%82%B8%E3%83%8A%E3%83%AB%E3%83%AA%E3%82%B9%E3%83%88%E3%81%AB%E7%99%BB%E9%8C%B2%E3%81%97%E3%81%9F%E3%83%95%E3%83%AC%E3%83%BC%E3%82%BA%E3%81%A0%E3%81%91%E3%82%92%E5%87%BA%E9%A1%8C%203.%20%E3%82%AF%E3%82%A4%E3%82%BA%E7%B5%90%E6%9E%9C%E3%81%AE%E3%83%95%E3%82%A3%E3%83%BC%E3%83%89%E3%83%90%E3%83%83%E3%82%AF))  with immediate feedback for learning reinforcement ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E5%AD%A6%E7%BF%92%E5%B1%A5%E6%AD%B4%E3%81%AB%E5%9F%BA%E3%81%A5%E3%81%84%E3%81%A6%E5%BE%A9%E7%BF%92%E3%82%92%E8%87%AA%E5%8B%95%E6%8F%90%E6%A1%88)) 
- A content-driven approach where adding new phrases or lessons is easy via JSON (matching the spec’s emphasis on content reuse and combination via JSON definitions ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=%E3%83%AC%E3%83%83%E3%82%B9%E3%83%B3%E5%8D%98%E4%BD%8D%E3%81%A7%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81%E3%82%AF%E3%82%A4%E3%82%BA%E3%82%84%E3%80%81%E3%82%B9%E3%83%94%E3%83%BC%E3%83%89%E5%BD%A2%E5%BC%8F%E3%81%AE%E9%80%A3%E7%B6%9A%E3%82%AF%E3%82%A4%E3%82%BA%E3%81%AA%E3%81%A9%E8%A4%87%E6%95%B0%E3%83%A2%E3%83%BC%E3%83%89%E3%81%AB%E5%AF%BE%E5%BF%9C%204))  ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=,%E3%82%A2%E3%82%A6%E3%83%88%E3%83%97%E3%83%83%E3%83%88%E5%AD%A6%E7%BF%92%E3%82%BF%E3%82%B9%E3%82%AF%EF%BC%88%E6%8F%90%E7%A4%BA%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%EF%BC%9A%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E8%A1%A8%E7%A4%BA%E3%81%AE%E6%9C%89%E7%84%A1%E3%80%81%E9%9F%B3%E5%A3%B0%E8%A1%A8%E7%A4%BA%E3%81%AE%E6%9C%89%E7%84%A1%E3%80%81%E3%83%9E%E3%82%B9%E3%82%AD%E3%83%B3%E3%82%B0%E7%AE%87%E6%89%80%E3%81%AA%E3%81%A9%EF%BC%89)) .
- Scalability for future enhancements: our architecture could integrate real APIs (for voice or data) by replacing the mock services, and could extend to community or AI features mentioned in the spec ([japanese-app/README.md at main · FriendlyTech-Inc/japanese-app · GitHub](https://github.com/FriendlyTech-Inc/japanese-app/blob/main/README.md#:~:text=1.%20%E5%AD%A6%E7%BF%92%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E9%AB%98%E5%BA%A6%E5%8C%96%20,%E5%BA%83%E5%91%8A%E3%83%A2%E3%83%87%E3%83%AB%E3%81%A8%E3%81%AE%E3%83%90%E3%83%A9%E3%83%B3%E3%82%B9%E3%82%92%E8%80%83%E6%85%AE%E3%81%97%E3%80%81%E5%AD%A6%E7%BF%92%E4%BD%93%E9%A8%93%E3%82%92%E6%90%8D%E3%81%AA%E3%82%8F%E3%81%AA%E3%81%84%E5%BD%A2%E3%81%A7%E3%81%AE%E5%B0%8E%E5%85%A5%E3%82%92%E6%A4%9C%E8%A8%8E)) without fundamental changes in structure.

By adhering to these design principles and best practices, the resulting mock app will be well-organized, **easy to maintain**, and true to the intended learning experience described in the requirements.
